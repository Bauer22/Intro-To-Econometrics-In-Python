{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Chapter 2\n",
    "\n",
    "## Goals:\n",
    "\n",
    "The goals for the this lab are to use real data to explore important concepts in Chapter 2 of Wooldridge using real\n",
    "data. In this lab we will explore concepts related to:\n",
    "\n",
    "\n",
    "• Estimates and Estimators with ordinary lease squares\n",
    "\n",
    "• Sampling Distribution\n",
    "\n",
    "• Residuals and Fitted Values\n",
    "\n",
    "## Basics\n",
    "\n",
    "1. Always include your import statements. Remember that you can add to the import statements at any time,\n",
    " as long as you rerun your code after. As always, copy and pasting what is inside these notebooks will\n",
    " suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will be using the data from the National Longitudinal Survey - J. R. Kling (2001) “Interpreting\n",
    "Instrumental Variables Estimates of the Return to Schooling,” Journal of Business and Economic Statistics,\n",
    "19, 358-364. This dataset contains a random sample of data on wages, education, location as well as many\n",
    "control variables. There are two files associated with this dataset: “Data66.dat” and “Data66.dct”.\n",
    "\n",
    "I complied them in Stata into Tutorial3.dta it is in the github repo\n",
    "\n",
    "2. Lets take a look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>black</th>\n",
       "      <th>imigrnt</th>\n",
       "      <th>hhead</th>\n",
       "      <th>mag_14</th>\n",
       "      <th>news_14</th>\n",
       "      <th>lib_14</th>\n",
       "      <th>num_sib</th>\n",
       "      <th>fgrade</th>\n",
       "      <th>mgrade</th>\n",
       "      <th>...</th>\n",
       "      <th>intmo66</th>\n",
       "      <th>nlsflt</th>\n",
       "      <th>nsib</th>\n",
       "      <th>ns1</th>\n",
       "      <th>ns2</th>\n",
       "      <th>ns3</th>\n",
       "      <th>ns4</th>\n",
       "      <th>ns5</th>\n",
       "      <th>ns6</th>\n",
       "      <th>ns7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>5222.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>5223.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>5224.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>5225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5226 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  black  imigrnt  hhead  mag_14  news_14  lib_14  num_sib  fgrade  \\\n",
       "0        1.0    1.0      0.0    5.0     1.0      1.0     1.0      1.0     NaN   \n",
       "1        2.0    1.0      0.0    1.0     0.0      1.0     0.0      7.0     NaN   \n",
       "2        3.0    0.0      0.0    1.0     1.0      1.0     1.0      1.0     8.0   \n",
       "3        4.0    0.0      0.0    1.0     1.0      1.0     1.0      2.0    14.0   \n",
       "4        5.0    0.0      0.0    1.0     0.0      1.0     1.0      NaN    11.0   \n",
       "...      ...    ...      ...    ...     ...      ...     ...      ...     ...   \n",
       "5221  5222.0    0.0      0.0    2.0     0.0      1.0     0.0      2.0     6.0   \n",
       "5222  5223.0    1.0      0.0    1.0     1.0      0.0     0.0      9.0     3.0   \n",
       "5223  5224.0    1.0      0.0    1.0     0.0      0.0     0.0      6.0     0.0   \n",
       "5224  5225.0    1.0      0.0    6.0     0.0      0.0     0.0      6.0     NaN   \n",
       "5225     NaN    NaN      NaN    NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "\n",
       "      mgrade  ...  intmo66  nlsflt  nsib  ns1  ns2  ns3  ns4  ns5  ns6  ns7  \n",
       "0       11.0  ...     11.0     1.0   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1        NaN  ...     11.0     1.0   6.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2        8.0  ...     11.0     1.0   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       12.0  ...     11.0     1.0   2.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       12.0  ...     11.0     1.0   3.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "...      ...  ...      ...     ...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "5221     8.0  ...     11.0     1.0   2.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5222     2.0  ...     11.0     1.0   9.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "5223     6.0  ...     11.0     1.0   6.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "5224     NaN  ...     11.0     1.0   6.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "5225     NaN  ...      NaN     NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5226 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata(\"C:/Users/patri/Desktop/Metrics TA/Intro-To-Econometrics-In-Python/Datasets/Tutorial3.dta\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are so many columns that we cannot see all of the column names when we preview. We can change our default\n",
    "preivews by adding\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can just print all the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "black\n",
      "imigrnt\n",
      "hhead\n",
      "mag_14\n",
      "news_14\n",
      "lib_14\n",
      "num_sib\n",
      "fgrade\n",
      "mgrade\n",
      "iq\n",
      "bdate\n",
      "gfill76\n",
      "wt76\n",
      "grade76\n",
      "grade66\n",
      "age66\n",
      "smsa66\n",
      "region\n",
      "smsa76\n",
      "col4\n",
      "mcol4\n",
      "col4pub\n",
      "south76\n",
      "wage76\n",
      "exp76\n",
      "expsq76\n",
      "age76\n",
      "agesq76\n",
      "reg1\n",
      "reg2\n",
      "reg3\n",
      "reg4\n",
      "reg5\n",
      "reg6\n",
      "reg7\n",
      "reg8\n",
      "reg9\n",
      "momdad14\n",
      "sinmom14\n",
      "nodaded\n",
      "nomomed\n",
      "daded\n",
      "momed\n",
      "famed\n",
      "famed1\n",
      "famed2\n",
      "famed3\n",
      "famed4\n",
      "famed5\n",
      "famed6\n",
      "famed7\n",
      "famed8\n",
      "famed9\n",
      "int76\n",
      "age1415\n",
      "age1617\n",
      "age1819\n",
      "age2021\n",
      "age2224\n",
      "cage1415\n",
      "cage1617\n",
      "cage1819\n",
      "cage2021\n",
      "cage2224\n",
      "cage66\n",
      "a1\n",
      "a2\n",
      "a3\n",
      "a4\n",
      "a5\n",
      "a6\n",
      "a7\n",
      "a8\n",
      "a9\n",
      "a10\n",
      "a11\n",
      "ca1\n",
      "ca2\n",
      "ca3\n",
      "ca4\n",
      "ca5\n",
      "ca6\n",
      "ca7\n",
      "ca8\n",
      "ca9\n",
      "ca10\n",
      "ca11\n",
      "ca12\n",
      "g25\n",
      "g25i\n",
      "intmo66\n",
      "nlsflt\n",
      "nsib\n",
      "ns1\n",
      "ns2\n",
      "ns3\n",
      "ns4\n",
      "ns5\n",
      "ns6\n",
      "ns7\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Often times datasets are missing information, or you want to concentrate on a sample of individuals where\n",
    "information is available for all variables you are interested in. In these cases it is necessary to “clean” the\n",
    "dataset to get it ready for analysis. You’ll want to “drop” observations that are missing key variables, or\n",
    "simply “keep” the observations that have all the information needed. Lets drop observations which have\n",
    "missing values for education, wage or who were not at the first interview.\n",
    "\n",
    "    There are many ways to do this, including built in functions\n",
    "\n",
    "    First to access a column and delete rows based on a conditional we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# overwrite the df into a new df with the same name\n",
    "# In the new df, we only have instances where nlsflt is not 0\n",
    "df = df[df.nlsflt != 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use built in functions.\n",
    "\n",
    "df.dropna will drop any none types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['grade76','wage76','nlsflt'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates, Estimators, and Hypothesis Testing\n",
    "\n",
    "1. We are interested in the relationship between(hourly) wages (wage76) and years of education (grade76). Lets\n",
    "first calculate the summary statistics of these two variables using the .describe function we learned from a prior lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wages:\n",
      " count    3010.000000\n",
      "mean        1.656664\n",
      "std         0.443798\n",
      "min         0.000000\n",
      "25%         1.371825\n",
      "50%         1.681750\n",
      "75%         1.958350\n",
      "max         3.179700\n",
      "Name: wage76, dtype: float64 \n",
      "\n",
      "grades:\n",
      " count    3010.000000\n",
      "mean       13.263455\n",
      "std         2.676913\n",
      "min         1.000000\n",
      "25%        12.000000\n",
      "50%        13.000000\n",
      "75%        16.000000\n",
      "max        18.000000\n",
      "Name: grade76, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#\\n prints on a new line\n",
    "print(\"wages:\\n\",df['wage76'].describe(), '\\n')\n",
    "\n",
    "print(\"grades:\\n\",df['grade76'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these statistics we see that there are 3010 observations left in our sample after dropping the observations above. The average person in our sample has 13 years of education, with the largest value being 18, and perhaps surprisingly a person in our sample reports having just one year of education. Turning to wages we see that average earning in our sample is approx. $\\$1.65$ an hour, with the highest hourly wage being over $\\$3.17$, and the lowest reporting receiving $\\$0$ an hour.\n",
    "\n",
    "\n",
    "2. To get an initial understanding of the relationship between wages and education we can calculate the\n",
    "correlation as well as the covariance between these two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31422552838961576"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we learned in the first tutorial:\n",
    "df['wage76'].corr(df['grade76'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37330262484722054"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wage76'].cov(df['grade76'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive correlation between these two variables would indicate that wages are high when education levels\n",
    "are high (and vice versa). A positive covariance implies that when years of education is above the mean then\n",
    "wages are above the mean (and vice versa). Remember, this does not imply causation, it simply gives us an\n",
    "idea about the relationship between levels of education and wage levels.\n",
    "\n",
    "\n",
    "3. To get a visual understanding of the relationship between the two variables, create a scatterplot where\n",
    "“wage76” is on the Y-axis and “grade76” is on the X-axis. Refer to the first tutorial if you need a refresher on\n",
    "how to create a scatter plot. The plot will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each of the dots on the scatter plot represents one of the observation in our dataset. OLS uses a an intercept, $\\widehat{β}_{0}$, and slope, $\\widehat{β}_{1}$, to minimized the sum of the (squared) distance between each of the dots and this regression line. To get an idea of this relationship, we can add a linear prediction to this scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtGklEQVR4nO3de3Tb1ZUv8O+2LCd2Xk5iJwQnjp0HTh1bJsGFcGnL69LwxoUACVBIKaSd1d6Z3s5kFpQuCCzuAprezjBDb1mhZVoGSrk86oZpWtpeMlNKSUog2M6z5B2bkDhx3nFiW973D8mKJf9+sn7yln7n99P+rOUV5+hn+ViWt4722eccYmYopZTyvjy3O6CUUkqGBnSllPIJDehKKeUTGtCVUsonNKArpZRP5Lv1jUtKSriiosKtb6+UUp70wQcfHGTmUqvbXAvoFRUVWLdunVvfXimlPImIdtvdpikXpZTyCQ3oSinlExrQlVLKJzSgK6WUT2hAV0opn3CtykUppXJN4/o2LH9rKz450olziwuxdH4VGuaUid2/BnSllMqCxvVtePCNFnR2hwEAbUc68eAbLQAgFtQ15aKUUlmw/K2tsWDep7M7jOVvbRX7HhrQlVIqCz450umoPR0a0JVSKgvOLS501J4ODehKKeM0rm/DJU++jcoHfo1Lnnwbjevb3O7SkC2dX4XCYCCurTAYwNL5VWLfQydFlVJGycbkoRv6+q5VLkqpnJFs8tDLAR2IBPVM/gwa0JXysEzXNbshG5OHfqUBXSmP8mtq4tziQrRZBO90Jg/9+IKXjE6KKuVR2ahrdoPU5GHfC17bkU4wzr7g+WGC1c6gAZ2IhhPRX4ioiYg2EtGjFtcMI6JXiGgbEa0looqM9FYpFePX1ETDnDI8cXMtyooLQQDKigvxxM21jkfWfn3BSyaVlMsZAFcw8wkiCgL4ExH9hpnX9LvmqwAOM/MMIloI4CkAt2egv0qpKMnUhGkkJg9NfMHLdApo0BE6R5yI/jcY/eCEy24C8LPo568BuJKISKyXSqkBslHX7GVjCoOO2jMtGymglHLoRBQgoo8AHADwe2Zem3BJGYC9AMDMPQCOAhhvcT9LiGgdEa1rb28fUseVynUNc8pwywVlCETHTgEi3HJBZsviBmPSgiC7IWU6Q02Jn8uYvVyYOczM5wOYDOBCIqpJ55sx8wpmrmfm+tJSy0OrlVIpalzfhtc/aEOYI2+Yw8x4/YM214KoaZOQh091O2q3I/VzWaXHkrWnw1GVCzMfAbAawNUJN7UBmAIARJQPYAyAQwL9U0rZMG3Sz7T+BGyG4nbtdqR+Lqn+JJNKlUspERVHPy8EcBWALQmXrQRwT/TzBQDeZubEPLtSSpBpk36m9SdsE4Ls2u1I/VxS/UkmlRH6JACriagZwPuI5ND/g4geI6Ibo9f8BMB4ItoG4NsAHhDroVLKUjZ273PCtP6U2Xxfu3Y7UpOrUv1JJpUql2ZmnsPMIWauYebHou0PM/PK6OenmflWZp7BzBcy8w6xHiqlLJlW5eLX/khNrl4+y3re0K49HbpSVCmPklqA4+f+SFQBHbGZRLVrt7N6i3Vln117OnQvF6U8LNO79zllUn/sqoDqp45z1EepBVzGVbkopZRXSFWnLJ1fhWAgPr8SDJBrqZtkNKArpXxJtOomsRAljcIUu2IWyXpADehKKTEmrRSVqrpZ/tZWdPfGR93uXjZyky8N6EopEY3r27D01aa4FZVLX21KK6hLvDBIVblIjfSLbcoc7drToQFdKSVi2cqNliPZZSs3OrofqaX2UlU3UiP9ZTfORjAvIRefR1h242xH95OMBnSllIgjnTblfTbtdkzbQkBqpN8wpwzLb62Le4FZfmudHhKtlPIvqRRHXwqo711DXwoIcHZEX9+1XjjKTgO6UkrE2KKg5U6GY4uc5Yil6r6TpYCcBmOJ+nqpF5hkNOWilIeZVFXyyA2zLeu1H7nBWY5YKsUhlQKSIjXHkIyO0JXyqL7Jw758c9/kISA34nNCKjXhpRSHE9l4gdGArpRHJZs8dHP/FInvLXE/UikgL9GUi1IelY29QbysetIoR+2ZFrBZ4m/Xng4doSulxGT6VHsn3tvR4ag908I2S/zt2tOhAV0pJSIbVRxO9NoESrv2ZEx6oUpGUy5KKRHZqOJwQ+P6Nix9LWFLg9fS29Ig03SEroznldGRl0k8xqaVCRKsN0V0mrJ+9M2N6E7Ii3SHGY++6byePdM0oCujmVaa50d+fYztMitOMy5WlTLJ2u0EiCwPhA4IboiuKRdlNNP29fAjqcdY8gAHiQVTdoFSMoA6UTLSulzSrj0dGtCV0UQPKfCZu+aVO2q3I/UYSx3gILXbotVoOFm7Haltb/cf73LUng4N6MpoUluX+tHjDbW4ZPq4uLZLpo/D4w21ju5H6jEus7nert2Oae/Krq+b5KjdTYMGdCKaQkSriWgTEW0kor+zuOYyIjpKRB9FPx7OTHdVrpHa18OPGte34cM9R+PaPtxz1PFIVuoxvnxWqaN2O6a9K1u9pd1Ru5tSGaH3APh7Zq4GMA/AN4io2uK6d5j5/OjHY6K9VDlL6pACP5IayTbMKcMtF5TFcssBItxygfOl91KBz7R3Zaa9wCQzaJULM+8DsC/6+XEi2gygDMCmDPdNKQBy+4P4jdTS/8b1bXjl/b2x3HKYGa+8vxf1U8c5etyl+nP5rFK8uGaPZbsTo4cFcOxM2LLdCantfLPBUQ6diCoAzAGw1uLmi4moiYh+Q0SW+2US0RIiWkdE69rbzXu7olQuSlZn7YRUVYnUSN8qmCdrtyOVSsqGlAM6EY0E8DqAbzHzsYSbPwQwlZnrAPwrgEar+2DmFcxcz8z1paXmPRhK5SKpOmupqhLTUhx+y6GDiIKIBPOXmPmNxNuZ+Rgzn4h+vgpAkIhKRHuqlDKaXTBxWkpXbLO9rV17ppn2ApNMKlUuBOAnADYz8w9srjkneh2I6MLo/R6S7KhSKjPsEiJOl9/0Omy3I1XPLsW0SdpkUln6fwmALwNoIaKPom3fAVAOAMz8LIAFAP6GiHoAdAJYyOzWw6+UckJqibyUozZ7v9i1Z5rUJG02pFLl8icM8mLNzM8AeEaqU0qp7DHtZB/Tqkp8l0NXSvmXaSkO0xaTeelkKA3oSrlAYvMpKVLb3kptztUwpwxzy8fEtc0tH+PaWgTJTccyTbfPVcYzbT/0ofbHtO1qpfYNlxrpf7exBe9ujz8m7t3tHfhuY4vjfWokmPYOJhkdoSujSe28Z1J/TNt8yrRJ0ZfX7nXUrs7SgK6MJhn8JNIcEv3xUl2zE1KpCakFSrlIUy7KaFLBTyrNITFBVmxTVeLWwhkpUqkJIuuvMTFnbRodoSujSS3qkBrpS+xX4qWcrBNSe7kU5luHJbt2dZY+QspoS+dXDXiS5kXbnZAa6UukA0w7TFmKVKrkVLf12lK7dnWWBnRltHW7OwYsHe+NtjshNdK3W2zjZBGOaWddKv/QgK6MJlXxILVYRSJdopN+KlN0UlQZTSr49U18DrWeXWKfEdOW2psmj4Bei19vnr6BGZQGdGW0AJFl8E4nPSFx8pHEPiN+nRSVErAJ6AEN6IPSlIsy2qKLpjhqzzSJ1I1fJ0Wl2M196pzo4HSErozWt9T75bWRMy8DRFh00ZS0loBLbCHQMKcM63Z3xPXH6YHKku86lOpPA7oy3uMNtUPew0NqYVHj+ja8/kFb3IHKr3/Q5uhAZZ0UVZmiKReVMVI7CpqyZF/qfsps8u127UqlSkfoKiMkR8SmLNkHZBYoVYy3nlitGK8BXQ2NjtBVRpg0IgbkFvNIHGC8ZsdhR+1KpUoDusoIqaX2Ji3ZB3RhkTKbBnSVEVJL7YsKAo7a7RQX2oysbdrtmHaAsVL9aUBXGSG11P5UV9hRux2pvbqlXqiUygQN6CojGuaU4Ymba1FWXAhCpILjiZtrHdd9S52mc8RiqX2ydjumHWCsVH+DVrkQ0RQALwCYiMjf0QpmfjrhGgLwNIBrAZwCsJiZP5TvrvISiaX2UotwJJbsAzILi5TKlFRG6D0A/p6ZqwHMA/ANIqpOuOYaADOjH0sA/Ei0lyqrTDqRXmrpv11JoNNSwcb1bXjl/b1xC4teeX+vq4+RUn0GDejMvK9vtM3MxwFsBpA4HLkJwAscsQZAMRFNEu+tyjjTDmV+vKEWd80rj43IA0S4a16545WjUqWCj765Ed3h+HcM3WHGo29udHQ/SmWCo4VFRFQBYA6AtQk3lQHov0F1a7Rt31A6p7IvWd23W2kFiaX/UqWCVtveJmtXKptSDuhENBLA6wC+xczH0vlmRLQEkZQMysvL07kLlWEmnkh/53Pv4d3tZ08oumT6OLx0/8WO7kM3xFK5IKUqFyIKIhLMX2LmNywuaQPQP6k5OdoWh5lXMHM9M9eXlpam01+VYaaV5SUGcwB4d3sH7nzuPUf3UzLSut7crt1O0OYvxq5dqWwa9GkYrWD5CYDNzPwDm8tWAribIuYBOMrMmm7xoMtnWb/Q2rVnWmIwH6zdzv7jXY7a7fTYZGjs2pXKplRSLpcA+DKAFiL6KNr2HQDlAMDMzwJYhUjJ4jZEyha/It5TlRWrt7Q7ak9GYv9x0+hpQ8pkgwZ0Zv4TgKSJRmZmAN+Q6pRyj9SuhFK7JCrlJ8yMnqP7QYF85I8qEb9/3T5XxZGaPDSxWkYCwXqVqk6tqkTHjx/Hhg0b0NzcjKamJny68r/Q1b4T3NWJ0fMWYOyli8W/pwZ0FUeqvE+qWqYwmIdOi8MkCx3OQo4tClqWFo51sO0tILcVgfKP3t5e7Ny5E01NTWhubo59bN++PXbN6NGjgdGTMbLmCgRLKzF88uyM9EUDuopTZrNE3ulpOlJL7YcHA5YBfXjQ2W6Lp7utN/Oya1fKSu+ZU+hq34nuA7vQ1b4TF//X42hpacHJkycBAESEmTNnYu7cuVi8eDFCoRDq6upQXl6OygdXZbx/GtBVnKXzq+Jy30B6m09J3Y/UQh6rF4Vk7Sq3hcNhbN++Hc3NzTjyzuvoOrATXe27ED66P3ZN3rARGDavHvfeey9CoRBCoRBqampQVFTkWr81oKs4ffntoVanSN2PUpl2+PBhtLS0xHLdzc3N2LBhA06dOhW5gPIQHFeGYZPOQ0HdfAQnVKKgtAKBUSX4z6eud7fzCTSgqwEkdkkEgHW7O/Dp0dNgAJ8ePY11uzs0oCvXcG8YPR2foKt9Jx566M+xAL5379ldS8aPH4+6ujosWbIkNur+0s93Iy84zMWep04DusqI7za24MU1e2L/DzPH/u9kX5Y8AnotZhzzHJaVDMvPw5megemVYfm6xNOPDh06hNO7m6Opkp3obt+F7oN7wD2RhWTfW5WPWbNm4fOf/3wszx0KhTBp0iRQQkVX3qufuvEjpEUDusqIl9futW13EtCH5VtXuTgNxF0WwTxZu/KG7u5ubN26Na66pKmpCZ988knsmryiMSgorcSoOdchOKECBaWV2PnsEgwb5o1RtxMa0FVGSJU/nraZtLRrt6Plht4XPnkEf/jDH+Jy3Zs2bUJXV2TUHQwGUV1djSuvvBKhUAjL3z+NggkVCIwYO+C+/BjMAQ3oynBjCoM4YnEA8xiHhzsr7+BwN7oPtaKrfRe6D+xE14FIyiR88jCueiZyzaRJkxAKhXDVVVfF0iVVVVUoKCiI3c8zD/zapZ/APRrQldGkDndW5mFm7N+/P27E3dzcjD0bNgG9PZGLAvkoKJmK4ZUXoGBCBV79zkKEQiHobq3WNKCrjJBamakHSvjDmTNnsHnz5ljg7vu3vf3spm+TJ09GKBTCrqLzUFBaieCESgTHlYHyzi4iu/LKK93ovmdoQFcZIbUroR5M4S3MjPCJQ9GVlLuiqyp3YsT32xAORxaZDR8+HDU1Nbjhhhti6ZLa2lqMHz8eAFCRg6kSKRrQVUYctch7J2u3IzW5quR1dnZi06ZNZzef+uVqdLfvQm/n2QPNAqNLUTChEt/+2pdj5YEzZsxAIOBs6waVGg3oKiOk9nJR7mNmtLa2Dsh1b926Fb29kWqjoqIi8JgpKDrvYgRLK1AQXU2ZN3wkAODxx69z80fIGRrQVUZI7eWisqu3+zS6D+6JVZZcdtlyNDc34/Dhw7FrKioqUFdXhwULFsRSJtOmTcP0h37rYs8V4LGA7scTcPxK93KxlwfAqoo+m2tWmRl79uxBU1MTjvz51djugT2H9wEc6R0Fh6Orfg5uu+22WLqkpqYGY8aMyWJPlROeCeh6Ao73SOwJk59H6LFY+5/vdO2/QeyWRGVqzeqJEydiBy30T5scO3Y2151fPAnBCRUYMesLKJgQqTDJL56IPz91Q4Z6pTLBMwHdryfgqOSsgnmy9lzG3IueowfQfWAnHn10XdxBCxydRB41ahRCoRDuvPPOWLrk9v/birxh7m35quR4JqBLnYCjskdTZJlz7NgxnG7djO72syspu9p3gbsifw+PNhJmzJiB888/H3fffXds58CKioqBm0/9SssE/cIzAV2rJrylcX0blr7WhO5wZGTYdqQTS19rAqApMid6e3tjBy30T5fs3Lkzdg0NG4GC0gqMrLkyVmGy7Udfw4gRI1zsuXKDZwK6Vk14y6NvbowF8z7dYcajb27UgG6j9/QJvPPOO3GlgS0tLbGDFvLy8nDeeefhs5/9LO677z7884dnIptPjSodMOrWYJ6bPBPQtWrCW/y6ZH/iqALsP95l2Z4q7g2j5/C+2LFmfWmT8LF2fOHpyDXjxo1DKBTC/fffH0uXzJ49G4WFZ9+RrtAVlSrBoAGdiJ4HcD2AA8xcY3H7ZQB+BaDvPeAbzPyYYB9jpE7SUSpdVsE8WXtHR8eAvbr3ftQcO2gBlIfg+MkYVlaNgjkVeOkfb0NdXR3OPffcAaNupQaTygj9pwCeAfBCkmveYWazDtdTKou4Nxy3DL4vgLe2tsauKSkpQV1dHUaefw0KJkxDwYQKBMdPAeWfHd1fe+21bnRf+cSgAZ2Z/0hEFVnoi1KeED51tN9e3dGUycE9mL08kk7Kz8/HZz7zGVx22WWxdEldXR0mTpwIItLNp1TGSOXQLyaiJgCfAPgHZt5odRERLQGwBADKy8uFvrVSmdHd3Y0tW7bEpUta330f4RMdsWsCI8YiWFqB0RfcgGe+2YC6ujrMmjUr7qAFpbJFIqB/CGAqM58gomsBNAKYaXUhM68AsAIA6uvrdWWIjxUGrc8CLQyaeSiz1UELmzZtQnd3ZNRdUFCA6upqDK84P7JXd7Q8MDCiOHYfX/6ybkCl3DXkgM7Mx/p9voqI/g8RlTDzwaHet/Iuu+k8t6f5uKcb3R17I4txont2T/y3e3HgwIHYNeeeey5CoRCuvvrqWMqkqqoKwWBQ0yXKaEMO6ER0DoD9zMxEdCEiewwdGnLPlKedsjnE2a7dTh4BVqv8B9vKhZmxb9++2Gj74Ju/iQTxjlagN7qWIRBEQelUXHfddbE8d21tLUpKShz1USlTpFK2+DKAywCUEFErgEcABAGAmZ8FsADA3xBRD4BOAAuZ9fQBN/hxqb3dli3920+fPm1ZYXLw4Nk3iYFRpSiYUIHCGRdG9+quRP64c0F5ATz/pKZKlD+kUuWyaJDbn0GkrFG5SHI3SpNeGIJ5QN+gnpkRPn4IXe07EW7fiUWLXowdtNB3vFlhYSFqamrQ0NAQS5eEQiHMeerPrvRfqWzyzEpRlZzUbpRSLwxDPST61KlT2LhxIzrW/y5uA6re0ydi17w3dSrq6upw8803x1Im06dP1+PNVM7SgO4TUrtRSr0wPHLD7LjNuQAgGCA8csPsuOv6DlpITJd8/PHHsePNKDgcwZKpKKr6XGQxTvR4s13/dJujn00pv9OA7hNSu1FKvTA0zCnDut0deHntXoSZESDCl2rHY1JXK1as+HXccvijR4/Gvm7atGkIhUJYuHAhQqEQ/sdbh5BffA6IzCx3VMokGtB9Qmo3SokXht7eXqz49Rr89Oe/xYl9OyIrKtt3YvnhT7Ec8Qct3HHHHXHHm40aNSruvr79Fy0TVCpVGtB9wmpEfMsFzjczu3xWKV5cs8ey3crx48fR0tISlzJpaWnB8ePHo1cQ8sdOQkFpJUbMvgKTKquw6tG7MHXqVOTlDT7qLgrmWZY6Fhm6QEkNHRFgVSene5UNTgO6TzSub8PrH7QhHP1LCDPj9Q/aUD91nKOgvnpLu2X725v2Y1tN4YBc944dO2LXjBkzBqFQCPfccw9+/jEiZ1OWlCOv4OzovhNAZWVlyv2RqmdX3mFX9KzF0IPTgO4TUpOZnxzpRO+Zk2ePNYueBr+nfTdmPnQawNmDFurr63HvvffGUiZTpkyJbfm66sFVsReX/gI6zFIqY3IyoJtUZy3FKu+drB0AwuEwtm3bFrf51L53/oIzR/bHrskbPhLBCZU457PX4PGvXo9QKITq6moUFSU/VNgqmCdrV0oNXc4FdMkFOCYJECUdEXd0dKClpSUuXbJhwwZ0dkYCfiAQQFVVFT570Txs7RoHGl+OYGklAqPGo6ggH0/cXOvo8RmsP0opeTkX0KVSE6bpC57cG0Z3R1u0smQXutt3YcqLX7M8aOHrX/96bCVldXU1hg8fDkDmHYyO0JXKvpwL6FJ11iY4ePBgbLR96g+/xdHWbeg6uAcIR1do5gVQNKEcl155aSzPHQqFcM455yQ93kziqL8ym/LHMod18XkArKY/tcZFqYFyLqBLLcCRNNiIuLu7G1u3bo1LlzQ1NWHfvn2xa4rHlyIwajJGz70ewQmRvbqLSsrx/UX1ruzlIlUXP8ZmC4ExKW4hoFQuybmALhVopCTm9Pe07cPffn8NfjXxNHoP7UZTU1PcQQvBYBDV1dW46qqr4jafeu+TngFL7SngPF/duL4NS19tQnd0O8O2I51Y+moTAGdzDH3XDvWFwSqYJ2tXSprUu8R0t4J2IucCulSgAYY2ku3q6sLmzZux9Ilf4MDuv6Irupqy9+QRAJGTufsOWpg/f34sXdJ30EKi5f/2dlwwB4DuMDueG1i2cmMsmMfup5exbOVGx4+RROpGJ1eV2+xWPDhdCZHKVtBDlXMBHZAJNKlWyzAzPv300wELcjZv3oyenp7IRYEgCkrKUVhZH1mMM6ECw0orsOdf7ki5P+mULVo50mk98rVrT0YnV5U6KxurnnMyoEuwqpY51dmJR55/E0cuGB6X6+5/0MLkyZNRV1eH66+P1HQ/9ZdOdOSPB+XFb/nqdPLQNFLloVKTq0q5rbPHekxv154ODehpiGz5uhdd7ZHSwL7zKbs7WrGHe/EVnD1o4aabboo73mzcuHFx9zW8qs2onL4UqfLQpfOr8K1XPrJsV8pLsrGlgQb0QXR2dmLjxo0DUiYdHR2xawKjS1EwoRKF512McyqrsPLhOzBjxoyUDlqQyulLbWgkNQEklQJ6YtUm23YvrxtQuYcAWMVuydkgDehRzIy9e/cOKA3sf9BCUVERamtrsWDBAvDYcry1bxh47BTkDR8JIDKyfuLmWlRVZX/ysDDfOj9XmO8sFEtNAEnZf7zLUbtyj1/XDPQ/BjGx3Qm7gbjkbFBOBvSTJ09iw4YNcYHb7qCF22+/PZYymTZtWtyWrybtCdNps/ugXbtS0kwbDEgpyA+guyts2W4aXwd0ZsauXbsGBO5t27aBo/mJkSNHIhQKYdGiRbHSwJqaGowePXrQ+5cYWUsptlmAU6wLcJQakpMWwTxZux2tQ3fg+PHjsVF3/7RJ30ELRITp06cjFArhrrvuii3IqaioSOmgBdNJTbhcMn0c3t3eYdnuhF/ffit7Qz0Y3O+G5edZvmMe5jAtmsygAZ2IngdwPYADzFxjcTsBeBrAtQBOAVjMzB+K9TBBb28vdu7cOSBwb9++PXbN6NGjEQqFcPfdd8cCd01NDUaOHJmpbrnuqE2duF27nZfuvxhX/eA/8fGBk7G2mRNG4KX7L3Z0P6a9/S4uDFrW0hcXarCRUj1plOVgoHrSKIurc89pm/SnXXs6Uhmh/xTAMwBesLn9GgAzox8XAfhR9N+MePHFF3HPPfcAiIy6Z86ciblz52Lx4sWxXHd5eXnSzaf8SGqPmsb1bWg9fDqurfXwaTSubzMmvZQOu6dDjj1NMmrNjsOO2r1CqjolG/tIDRrQmfmPRFSR5JKbALzAkaT0GiIqJqJJzLwvydek7dJLL8Vzzz2Huro6zJ49e9CDFnKF1B41ft1eWPeEyTy/ruq9c1655Tm7d84rd3Q/2dhHSiKHXgZgb7//t0bbBgR0IloCYAkAlJc7ezD6TJ06Fffdd19aX+tnUvXsUtsLm7YHi2n9Ud7xeEMtAMQdwL7ooimx9lRJHeSeTFYnRZl5BYAVAFBfX+/tl20DSVTdSL0tnDdtrGU+dd60sY7uZ/SwAI6dGVhNMHqYs5Ixv44eVXbUTx2H1Vva8cmRTpwzZjjqpzorEgDkDnJPRiKgtwGY0u//k6NtxjKpflyyPybtY77rkPWI3q7dzsku6wkju3Y7OkLPPVK/c6l9ibKRzpSol1kJ4G6KmAfgaKby5xL6fjltRzrBOPvLaVzvzmuQVH+k7qdhThmeuLkWZcWFIEQ2wXJ6niggt/RfamStI3TvyLcpzLZrtyP1O08WiJ2Q+ptIJpWyxZcBXAaghIhaATwCIAgAzPwsgFWIlCxuQ6Rs8StivcsA0yb9pPoj+XPpPubKTWGbDcLt2jPNS/NKqVS5LBrkdgbwDbEeZZhpZ4pK9ce0n0tHxCpd2djzxAmpeaVs/E3k3MI9u1+CW2eKSvXHtJ/Lbr9y3cfcPHYjRH03FbF0fhUKg/GT8OnMK2XjbyLnArrUL8e0/iydX4VgQo4xmEdp/VyN69twyZNvo/KBX+OSJ99Oa35Bqj8zJ4xw1K6cW3TRFEftuUZqXknyb9SOb/ZySZXkmaLG9SdxQJXGAEtqRl+qP+022+TatXuBafML9VPH4edr98RtHJVHcFyaJ3XEmonbNIhtxCfwN5FMzgV0wKxdEgGZ/ix/a6vIIdGSk7QS/ZE849QUps0vLH9r64BdAHsZjn9XUkes+XWbBqm/iWRyLuXiV1KTolKlVaZN0prEbqTp1ghU6nclteOnX7dpyMbfhAZ0n5CaFJWaIJPqj93Wq17ekvVUV4+j9kwrtEmJ2LXb0cnV5LJRuKAB3SekJlel0gFS/XnkhtkIBhImkgKER26Y7eh+TNIVtn4s7dozTSpVYtrk6sRRBY7aMy0bBRka0H1CaiZeakQs1Z+GOWVYvqAu7n6WL6hzbQ7Ej/ldqVTJ4w21uGteeWxEHiDCXfPKHW9iJWXtQ1cNCN4TRxVg7UNXudIfqb+JZHJyUtSvJCZXpf64pfojeT8SpA7jNolk1c3jDbWuBXArbgVvO5l+Lnv3WagyQurkI78y6TBuuz9ep3/UdjtgOt0ZU4qJi9Ik1mZkg47QVZxsnKrilMQukmU2P5fTIGHS4yO1RH7TvuOO2pOR2vFz6WtNcSV+wUD6i+SG2p/G9W1Y+moTuqO1nW1HOrH01SYAaazNyDAdoas4pq2kldpFUurn6glbn/Ru125FqqpEKqBLlQmK7mSa+EOkkfKT6s+ylRtjwbxPdy9j2cqNzjuVYRrQVZxsTNw4IbV1qdTPtd9mhapdu5UzNtUjdu1eIfW7Wv7WVssAms79SPTHS4vbNOUyBKYdlCHFpElIycUYpvxcdrvAurQ7rNhSe9N2Ds3G/uOm0RF6mkw7KMOvTNtFUoJpC3CW3TjbctOoZTc6q/U3bedQqcfZ7lwNh+dtZIUG9DRJvZ1TyZmW05dgWlVJw5wyLL81odb/Vue1/lK/q8tnlTpqtyO1SM60d1TJaMolTbpXSXZk46R0JyRqtqXOWyVYzxWmM3CUSEdJ7Ry6eku7o3Y7UpVNUveTDTpCT5MfUwEmsjsp3a3UlsTydrHNsBy2Z0PDnDK8+8AV2PnkdXj3gSvSepGQenwkzxrwyrtEDehp8tIv2S0SizFMS21JLG8vttlGwa7djokLcCRIDZYkt58wqfIrGU25pMm0gzJMI3VQhomVCkNd3i61vcLS+VVxjzHgj0GF5M9lSmVTtmhAH4Jce7I4IXVQhmmn+0iQ2l7Br4MK034u0VO8MkwD+hD4tQ5dglQeVPJ0H1N+XyZtH2AqkwZLUoOTbEgph05EVxPRViLaRkQPWNy+mIjaieij6Md98l01i9ahJyeVB5XKE5v0+5KafzHpZ/IzL1W0DRrQiSgA4IcArgFQDWAREVVbXPoKM58f/fixcD+NY9pknWlMqzAw6fclNclm0s/kZ16qaEsl5XIhgG3MvAMAiOgXAG4CsCmTHTOdl1613SCVB5W6H9N+XxIpBRMnjP3IS5PPqQT0MgB7+/2/FcBFFtfdQkRfAPBXAP+TmfcmXkBESwAsAYDy8nLnvTWI5kEHZ9IBF378fUkuLFL2TJukTUZqUvRNAC8z8xki+hqAnwG4IvEiZl4BYAUA1NfXG7hwNnVeetV2ypTJQ0l+/H2ZuLDINFLPZZMmaZNJJaC3Aei/DG5ytC2GmQ/1+++PAXxv6F0zm5detZ3wUomWE379fSl7fn0uJ5NKQH8fwEwiqkQkkC8EcEf/C4hoEjPvi/73RgCbRXtpKK+8ajvhpRItp/z4+zKNSe/u/PxctjNoQGfmHiL6JoC3AAQAPM/MG4noMQDrmHklgL8lohsB9ADoALA4g31WGWTa5KHyDtNGxLn4XE4ph87MqwCsSmh7uN/nDwJ4ULZryg1+nDw0kcRIdkRBACe7Bh59N6IgYHF15pk2Is7F57JuzqXimLjpmFdOXE+V1IKgUxbBPFl7pplWRmnicznTNKCrOKbtLOfH1ZBSC4JMq3Ix7SQm057L2aB7uagBTJo8NO1tvAS/5nYl992RYtJzORt0hK6M5sfg56Wl5E74dX92L9GArozmx+Anldsda3Mghl17puVizto0GtCV0fwYJKRyu1IHZUjJxZy1aTSHrozm1xWeErldqYMyJOVazto0GtCV8fwYJCTq0HOxzlolpwHdACYtl1aZJ7Wi8vJZpXhxzR7LdpWbNKC7zLTl0n5mygunVCnm6i3tjtqV/+mkqMv01JnsMGmBklQpph9LOtXQaEB3mf5RZodJL5xSpZh+LOlUQ6MB3WX6R5kdJr1wmnbeqp/5bR+gwWhAd5n+UWaHSS+cUvXaWvednElptmwhdmkVQn19Pa9bt86V720aUybr/Cxx8hmIvHBqAPSvS55827Kss6y4EO8+MOCETM8gog+Yud7qNq1yMYAf66xN49cFSsqeZJrNK4MuDegqZ+gLZ26RWnjlpdJizaErpXxJan7KpAqpwegIXSnlS1JpNpMqpAajAV0p5VsSaTYv7ZmjKRellErCS6XFOkJXSqkkvFQhlVJAJ6KrATwNIADgx8z8ZMLtwwC8AOACAIcA3M7Mu2S7qtTQeKX0zMv8+hh7pUJq0JQLEQUA/BDANQCqASwiouqEy74K4DAzzwDwTwCeku6oUkORi6sGs00fY/elkkO/EMA2Zt7BzF0AfgHgpoRrbgLws+jnrwG4kohIrptKDY2XSs+8Sh9j96US0MsA7O33/9Zom+U1zNwD4CiA8Yl3RERLiGgdEa1rb9c9m1X2eKn0zKv0MXZfVqtcmHkFM9czc31pqZ6qorLHpM25/EofY/elEtDbAEzp9//J0TbLa4goH8AYRCZHlTKCl0rPvEofY/elUuXyPoCZRFSJSOBeCOCOhGtWArgHwHsAFgB4m93axlEpC14qPfMqfYzdl9L2uUR0LYB/RqRs8Xlm/l9E9BiAdcy8koiGA/h3AHMAdABYyMw7kt2nbp+rlFLODXn7XGZeBWBVQtvD/T4/DeDWoXRSKaXU0OjSf6WU8gkN6Eop5RMa0JVSyic0oCullE+4dkg0EbUD2O3KN3emBMBBtzvhkPY5O7zWZ6/1F9A+W5nKzJYrM10L6F5BROvsSoRMpX3ODq/12Wv9BbTPTmnKRSmlfEIDulJK+YQG9MGtcLsDadA+Z4fX+uy1/gLaZ0c0h66UUj6hI3SllPIJDehKKeUTGtABENEUIlpNRJuIaCMR/Z3FNZcR0VEi+ij68bDVfWUTEe0iopZofwZsXUkR/0JE24iomYjmutHPfv2p6vf4fUREx4joWwnXuP44E9HzRHSAiDb0axtHRL8noo+j/461+dp7otd8TET3uNjf5US0Jfp7/yURFdt8bdLnUJb7vIyI2vr97q+1+dqriWhr9Hn9gMt9fqVff3cR0Uc2X5udx5mZc/4DwCQAc6OfjwLwVwDVCddcBuA/3O5rQp92AShJcvu1AH4DgADMA7DW7T7361sAwKeILJIw6nEG8AUAcwFs6Nf2PQAPRD9/AMBTFl83DsCO6L9jo5+Pdam/XwSQH/38Kav+pvIcynKflwH4hxSeN9sBTANQAKAp8W81m31OuP1/A3jYzcdZR+gAmHkfM38Y/fw4gM0YeG6qF90E4AWOWAOgmIgmud2pqCsBbGdm41YLM/MfEdnXv7/+B6H/DECDxZfOB/B7Zu5g5sMAfg/g6kz1s49Vf5n5dxw53xcA1iBy0pgxbB7jVKRyaH1GJOszERGA2wC8nI2+2NGAnoCIKhA5qGOtxc0XE1ETEf2GiGZnt2eWGMDviOgDIlpicXsqB3y7ZSHsn/ymPc4AMJGZ90U//xTARItrTH2870XknZqVwZ5D2fbNaJroeZu0lqmP8ecB7Gfmj21uz8rjrAG9HyIaCeB1AN9i5mMJN3+ISHqgDsC/AmjMcvesfI6Z5wK4BsA3iOgLbncoFURUAOBGAK9a3Gzi4xyHI++hPVHvS0QPAegB8JLNJSY9h34EYDqA8wHsQySF4RWLkHx0npXHWQN6FBEFEQnmLzHzG4m3M/MxZj4R/XwVgCARlWS5m4l9aov+ewDALxF5O9pfKgd8u+EaAB8y8/7EG0x8nKP296Wrov8esLjGqMebiBYDuB7AndEXoQFSeA5lDTPvZ+YwM/cCeM6mL0Y9xgBARPkAbgbwit012XqcNaAjlv/6CYDNzPwDm2vOiV4HIroQkcfuUPZ6OaA/I4hoVN/niEyCbUi4bCWAu6PVLvMAHO2XNnCT7WjGtMe5n76D0BH991cW17wF4ItENDaaLvhitC3riOhqAP8I4EZmPmVzTSrPoaxJmN/5kk1fYofWR9/pLUTkd+Om/w5gCzO3Wt2Y1cc5G7PDpn8A+Bwib6GbAXwU/bgWwNcBfD16zTcBbERkVn0NgP/mcp+nRfvSFO3XQ9H2/n0mAD9EpCqgBUC9AY/1CEQC9Jh+bUY9zoi82OwD0I1IjvarAMYD+H8APgbwBwDjotfWA/hxv6+9F8C26MdXXOzvNkRyzX3P52ej154LYFWy55CLff736PO0GZEgPSmxz9H/X4tIJdp2t/scbf9p3/O337WuPM669F8ppXxCUy5KKeUTGtCVUsonNKArpZRPaEBXSimf0ICulFI+oQFdKaV8QgO6Ukr5xP8HXGfsq/Pwsg8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#As before create the graph\n",
    "plt.scatter( df['grade76'], df['wage76'])\n",
    "\n",
    "#This is creating a line of best fit.\n",
    "plt.plot( np.unique(df['grade76']), np.poly1d(np.polyfit(df['grade76'], df['wage76'], 1)) (np.unique(df['grade76'])), 'k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A quick explaination of the line of best fit code:\n",
    "\n",
    "The plot function takes in many different parameters. The first two will always be your x and y values np.unique(df['grade76']) means that our x's are all of the unique grade76 values\n",
    "\n",
    "The y values are created in this way:\n",
    "\n",
    "np.poly1d(np.polyfit(df['grade76'], df['wage76'], 1))(np.unique(df['grade76'])\n",
    "\n",
    "Polyfit creates a least squares polynomial fit of the x and y values. The 1 is the degree of polynomial we are using.\n",
    "\n",
    "Poly1d is creating a 1d polynomial. So given 1, 2, 3 it would act as 1x^2 + 2x + 3\n",
    "\n",
    "You don't need to worry too much about how the code works since you can just copy and paste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Next, lets run a regression to get an estimate of the relationship between schooling and wages.\n",
    "We’ll use “wage76” as our dependent variable (“Y ”), and “grade76” as our independent variable (“$X_{1}$”) to\n",
    "estimate the intercept, $\\widehat{β}_{0}$\n",
    ", and slope $\\widehat{β}_{1}$ parameters.\n",
    "\n",
    "I am using the OLS from statsmodel.api since it has a very verbose summary built in. You obviously can use\n",
    "any other regression like from sklearn.linear_model import LinearRegression, but you may need to define a function\n",
    "to get all of the outputs you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 wage76   R-squared:                       0.099\n",
      "Model:                            OLS   Adj. R-squared:                  0.098\n",
      "Method:                 Least Squares   F-statistic:                     329.5\n",
      "Date:                Thu, 07 Jan 2021   Prob (F-statistic):           5.76e-70\n",
      "Time:                        12:48:33   Log-Likelihood:                -1668.8\n",
      "No. Observations:                3010   AIC:                             3342.\n",
      "Df Residuals:                    3008   BIC:                             3354.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9657      0.039     24.871      0.000       0.890       1.042\n",
      "x1             0.0521      0.003     18.153      0.000       0.046       0.058\n",
      "==============================================================================\n",
      "Omnibus:                       23.142   Durbin-Watson:                   1.725\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.349\n",
      "Skew:                          -0.186   Prob(JB):                     5.16e-06\n",
      "Kurtosis:                       3.236   Cond. No.                         68.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(df['grade76'].ravel())\n",
    "results = sm.OLS(df['wage76'], X).fit()\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the stata output for the same regression and talk about our results.\n",
    "\n",
    "![](Images/tut3reg.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient on “grade76” ($\\widehat{β}_{1}$) indicates that another year of education is predicted to cause hourly wage to increase by $.05.\n",
    "\n",
    "The coefficient for the constant ($\\widehat{β}_{0}$) shows the the predicted wage for someone with 0 years of education is approx. $0.97 per hour.\n",
    "\n",
    "While we probably think that the constant is not that useful in this application, remember that there were\n",
    "individuals in our sample with only one year of education.\n",
    "\n",
    "Keep in mind, we are unlikely getting the\n",
    "causal effect of a year on education as there are probably many other factors that are correlation with\n",
    "education that also influence hourly wages.\n",
    "\n",
    "The next column gives us the standard error of the parameters $\\widehat{β}_{0}$ and $\\widehat{β}_{1}$. This allows us to understand the sampling distribution of our OLS estimators, and will be extensively used going forward for\n",
    "hypothesis testing.\n",
    "The r-squared indicates that we are explaining just under 10% of the variation in hourly wages in 1976\n",
    "with years of education.\n",
    "\n",
    "Remember R2 = ESS/TSS = 1 − (SSR/TSS). We can individually see the calculation of\n",
    "ESS, SSR, SST in the top left panel of the stata results. We can see that ESS = 58.5, SSE = 534.1, SST = 592.6.\n",
    "\n",
    "We do not have this in our python output. But we can very easily get them using built in methods.\n",
    "\n",
    "If you need to find the full list of built ins for regression results with the OLS in stats model go to:\n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.RegressionResults.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESS:  58.516157978935325\n",
      "SSR:  534.1264577956593\n",
      "SST:  592.6426157745947\n"
     ]
    }
   ],
   "source": [
    "print(\"ESS: \", results.ess)\n",
    "print(\"SSR: \", results.ssr)\n",
    "print(\"SST: \", results.centered_tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Perhaps we think that a better way to think about the relationship between education and wages is that an\n",
    "increase in education causes wages to change by a certain %, rather than constant amount. To estimate this\n",
    "relationship, we should first generate a variable equal the the natural log of wages.\n",
    "\n",
    "The logical thing to do would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Note that in np, log is the natural log, and log10 is base 10\n",
    "df['lnwage'] = np.log(df.wage76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this gives us an error since we are trying to do ln(0)\n",
    "\n",
    "Stata automatically drops values of 0 when doing the ln calculations. We specifically need to drop the values.\n",
    "\n",
    "So you need to be very careful in your assignments when you are dropping 0's, incase you need to recalculate after.\n",
    "\n",
    "I would recommend doing a deep copy of the df and using that copy for any problem where you are dropping 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# So we need to drop the 0's\n",
    "df = df[df.wage76 != 0]\n",
    "# Then create ln wage\n",
    "df['lnwage'] = np.log(df.wage76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now we can estimate a regression with the natural log of hourly wages as our dependent variable and years\n",
    "of education as our independent variable. Follow the steps above, but use “lnwage” as as the dependent\n",
    "variable. We get the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 lnwage   R-squared:                       0.088\n",
      "Model:                            OLS   Adj. R-squared:                  0.087\n",
      "Method:                 Least Squares   F-statistic:                     288.9\n",
      "Date:                Thu, 07 Jan 2021   Prob (F-statistic):           6.17e-62\n",
      "Time:                        12:48:33   Log-Likelihood:                -624.04\n",
      "No. Observations:                3008   AIC:                             1252.\n",
      "Df Residuals:                    3006   BIC:                             1264.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0055      0.027      0.201      0.841      -0.048       0.059\n",
      "x1             0.0345      0.002     16.997      0.000       0.031       0.038\n",
      "==============================================================================\n",
      "Omnibus:                     1131.698   Durbin-Watson:                   1.768\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7464.885\n",
      "Skew:                          -1.634   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.991   Cond. No.                         68.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "================================================================================\n",
      "ESS:  25.63088573724241  SSR:  266.68655915268204  SST:  292.31744488992445\n"
     ]
    }
   ],
   "source": [
    "newX = sm.add_constant(df['grade76'].ravel())\n",
    "results = sm.OLS(df['lnwage'], newX).fit()\n",
    "print(results.summary())\n",
    "print('==' * 40)\n",
    "print(\"ESS: \", results.ess, \" SSR: \", results.ssr, \" SST: \", results.centered_tss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the results indicate that a one-year increase in schooling is associated with an approx. 3.4% increase\n",
    "in hourly wages. Notice that the change in the functional form of the dependent variable also changes the\n",
    "r-squared - we are explaining approx. 8.7% of the variation in the natural log of hourly wages with years of\n",
    "education.\n",
    "\n",
    "\n",
    "7. Lastly we need to construct the residuals (the OLS errors), fitted values, and other information\n",
    "from your (last) regression.\n",
    "\n",
    "We can use the .resid and .fittedvalues from the stats model api which are methods built into the results of our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.284318\n",
       "2       0.032102\n",
       "3       0.261402\n",
       "4      -0.472338\n",
       "5       0.266955\n",
       "          ...   \n",
       "5217   -0.229626\n",
       "5218   -0.002390\n",
       "5219    0.056442\n",
       "5220    0.255717\n",
       "5224    0.051821\n",
       "Length: 3008, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.resid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.246957\n",
       "2       0.419419\n",
       "3       0.419419\n",
       "4       0.384927\n",
       "5       0.419419\n",
       "          ...   \n",
       "5217    0.419419\n",
       "5218    0.453912\n",
       "5219    0.419419\n",
       "5220    0.419419\n",
       "5224    0.453912\n",
       "Length: 3008, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.fittedvalues\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
